# -*- coding: utf-8 -*-
"""CIC260-Tarefa05.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/tales-oliveira/CIC260-Tarefa05-Perceptron/blob/main/CIC260-Tarefa05.ipynb

#CIC260 - Inteligência Artificial

##Tales Oliveira
##Tarefa 05

###============================================================================================
###Importando a biblioteca numérica numpy
"""

import numpy as np

"""###Definindo a classe Perceptron"""

class Perceptron(object):
    def __init__(self, tAprendizagem=0.01, nIteracoes=50, random_state=1):
        self.tAprendizagem = tAprendizagem
        self.nIteracoes = nIteracoes
        self.random_state = random_state

    # Função para o aprendizado a partir do número de amostras e número de atributos do conjunto     
    def fit(self, X, y):
        rgen = np.random.RandomState(self.random_state)
        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1+X.shape[1])
        self.errors_ = []
        
        for _ in range(self.nIteracoes):
            errors = 0
            for xi, target in zip(X, y):
                update = self.tAprendizagem * (target - self.predict(xi))
                self.w_[1:] += update * xi
                self.w_[0] += update
                errors += int(update != 0.0)
            self.errors_.append(errors)
        return self
    
    # Função para calcular a entrada
    def net_input(self, X):
        return np.dot(X, self.w_[1:]) + self.w_[0]
    
    # Função para obter o rótulo da classe utilizando função degrau
    def predict(self, X):
        return np.where(self.net_input(X) >= 0.0, 1, -1)

"""###============================================================================================

### A biblioteca pandas é utilizada para o armazenamento de dados tabulados da base de dados Iris.
"""

import pandas as pd

df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None) # A base de dados é lida
df.tail() # O final do conjunto é exibido

"""###============================================================================================

### A biblioteca matplotlib é utilizada para visualizar parte do conjunto de dados.
"""

import matplotlib.pyplot as plt

y = df.iloc[0:100, 4].values 
# Vamos convertes os valores das classes em valores 1 ou -1.
# A classe 'Iris-setosa' será -1 e o restante 1
y = np.where(y == 'Iris-setosa', -1, 1)

X = df.iloc[0:100, [0,2]].values

"""### Exibindo a distribuição dos valores obtidos."""

plt.scatter(X[:50, 0], X[:50, 1],
           color='red', marker='o', label='setosa')
plt.scatter(X[50:100, 0], X[50:100, 1],
           color='blue', marker='x', label='versicolor')
plt.xlabel('comprimento da sépala [cm]')
plt.ylabel('comprimento da pétala [cm]')
plt.legend(loc='upper left')
plt.show()

ppn = Perceptron(tAprendizagem=0.1, nIteracoes=10)
ppn.fit(X, y) ## Chamada do método que faz o treino, passando as entradas (X) e suas respectivas saídas (y)

plt.plot(range(1, len(ppn.errors_) +1),
        ppn.errors_, marker='o')
plt.xlabel('Épocas')
plt.ylabel('Nº de atualizações')
plt.show()

"""###============================================================================================"""

# Importamos a biblioteca
from mlxtend.plotting import plot_decision_regions

# Plotamos o gráfico
plot_decision_regions(X, y, clf=ppn)
plt.title('Perceptron')
plt.show()

"""###============================================================================================

###SCIKIT
"""

from sklearn.datasets import make_blobs
# Vamos criar 2 blobs com 200 amostras e 2 dimensões e 2 centros.
blobs = make_blobs(n_samples=200, n_features=2, centers=2, random_state=42)
# Em seguida, vamos plotar os dados gerados para visualização.
plt.scatter(blobs[0][:,0], blobs[0][:,1], c=blobs[1])
plt.show()

ppn = Perceptron(nIteracoes=10, tAprendizagem=0.02)
X = blobs[0] # Entrada de dados
y = blobs[1] # Saída
# Apenas para substituir as classes 0 e 1 para 1 e -1
# A classe 1 é a que desejamos encontrar.
y[y == 0] = -1
ppn.fit(X, y) # Treinar

plt.plot(range(1, len(ppn.errors_) +1),
        ppn.errors_, marker='o')
plt.xlabel('Épocas')
plt.ylabel('Nº de atualizações')
plt.show()

plot_decision_regions(X, y, clf=ppn)
plt.title('Perceptron')
plt.show()

"""###============================================================================================"""

from sklearn.datasets import make_moons
# Vamos criar o conjunto com 100 amostras
moons = make_moons(n_samples=100)
plt.scatter(moons[0][:,0], moons[0][:,1], c=moons[1])
plt.show()

ppn = Perceptron(nIteracoes=10, tAprendizagem=0.5)
X = moons[0]
y = moons[1]
# Apenas para substituir as classes 0 e 1 para 1 e -1
# A classe 1 é a que desejamos encontrar.
y[y == 0] = -1
ppn.fit(X, y)
plt.plot(range(1, len(ppn.errors_) +1),
        ppn.errors_, marker='o')
plt.xlabel('Épocas')
plt.ylabel('Nº de atualizações')
plt.show()

ppn = Perceptron(nIteracoes=50, tAprendizagem=0.5)
ppn.fit(X, y)
plt.plot(range(1, len(ppn.errors_) +1),
        ppn.errors_, marker='o')
plt.xlabel('Épocas')
plt.ylabel('Nº de atualizações')
plt.show()

plot_decision_regions(X, y, clf=ppn)
plt.title('Perceptron')
plt.show()